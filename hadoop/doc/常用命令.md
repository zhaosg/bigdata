# Hadoop常用命令

标签： hadoop 大数据

---

## 1.格式化ZK(在任意的namenode上执行)
```
bin/hdfs zkfc -formatZK
```

## 2.在任意的namenode上执行

``` shell
sbin/hadoop-daemons.sh start journalnode
```

## 3.格式化
```
bin/hadoop namenode -format -clusterId cluster1
```


## 4.启动HDFS（在任意的namenode上执行）
```
sbin/start-dfs.sh
```
## 5.启动YARN(在任意的namenode上执行)
```
sbin/start-yarn.sh
```
## 5.查看状态(在任意的namenode上执行)

```
bin/hdfs  haadmin -getServiceState  nn01
bin/hdfs  haadmin -getServiceState  nn02
```


6.1) 格式化zk集群
  在h2master上执行hadoop2.5/bin/hdfs zkfc -formatZK   此操作仅仅表示和zk集群发生关联
  15/01/11 18:14:20 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/cluster1 in ZK.

6.2) 启动journalnode集群
  在h2master、h2master2、h2sliver112上分别执行hadoop/sbin/hadoop-daemon.sh start journalnode
6.3) 格式化namenode、启动namenode
  在h2master上执行bin/hdfs namenode -format
  在h2master上执行sbin/hadoop-daemon.sh start namenode
  在h2master2上执行bin/hdfs namenode -bootstrapStandby
  在h2master2上执行sbin/hadoop-daemon.sh start namenode
6.4)  启动datanode
  在h2master上执行hadoop/sbin/hadoop-daemons.sh start datanode   启动所有datanode节点
  此时访问如下链接
  http://h2master:50070/ http://h2master2:50070/
  两个namenode都是standby状态
6.5)  启动ZKFC (FailoverController) 必须是在namenode节点上启动 让zk来决定用哪个namenode作为active
  在h2master、h2master上 启动zkfc，执行命令sbin/hadoop-daemon.sh start zkfc
  此时访问   http://h2master:50070/ http://h2master2:50070/ 结果如下：
  Overview 'h2master:9000' (active)
  Overview 'h2master2:9000' (standby)
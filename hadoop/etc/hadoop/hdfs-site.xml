<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!--指定DataNode存储block的副本数量。默认值是3个，我们现在有4个DataNode，该值不大于4即可。-->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>

    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/data/hadoop/data</value>
    </property>

    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/data/hadoop/name</value>
    </property>

    <property>
        <name>dfs.namenode.handler.count</name>
        <value>8</value>
    </property>


    <!--使用federation时，使用了2个HDFS集群。这里抽象出两个NameService实际上就是给这2个HDFS集群起了个别名。名字可以随便起，相互不重复即可-->
    <property>
        <name>dfs.nameservices</name>
        <value>cluster1</value>
    </property>

    <!--指定NameService是cluster1时的namenode有哪些，这里的值也是逻辑名称，名字随便起，相互不重复即可-->
    <property>
        <name>dfs.ha.namenodes.cluster1</name>
        <value>nn01,nn02</value>
    </property>

    <!--指定nn01的RPC地址-->
    <property>
        <name>dfs.namenode.rpc-address.cluster1.nn01</name>
        <value>nn01:9000</value>
    </property>

    <!--指定nn01的http地址-->
    <property>
        <name>dfs.namenode.http-address.cluster1.nn01</name>
        <value>nn01:50070</value>
    </property>

    <!--指定nn02的RPC地址-->
    <property>
        <name>dfs.namenode.rpc-address.cluster1.nn02</name>
        <value>nn02:9000</value>
    </property>

    <!--指定nn02的http地址-->
    <property>
        <name>dfs.namenode.http-address.cluster1.nn02</name>
        <value>nn02:50070</value>
    </property>

    <!--指定cluster1的两个NameNode共享edits文件目录时，使用的JournalNode集群信息-->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://dn01:8485;dn02:8485;dn03:8485/cluster1</value>
    </property>

    <!--指定cluster1是否启动自动故障恢复，即当NameNode出故障时，是否自动切换到另一台NameNode-->
    <property>
        <name>dfs.ha.automatic-failover.enabled.cluster1</name>
        <value>true</value>
    </property>

    <!--指定cluster1出故障时，哪个实现类负责执行故障切换-->
    <property>
        <name>dfs.client.failover.proxy.provider.cluster1</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>

    <!--指定JournalNode集群在对NameNode的目录进行共享时，自己存储数据的磁盘路径-->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/opt/data/hadoop/journal</value>
    </property>

    <!--一旦需要NameNode切换，使用ssh方式进行操作-->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
    </property>

    <!--如果使用ssh进行故障切换，使用ssh通信时用的密钥存储的位置-->
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/zhaosg/.ssh/id_rsa</value>
    </property>
</configuration>